{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b0cefa9",
   "metadata": {},
   "source": [
    "# Integrazione wd_estimation.py con Dataiku DSS\n",
    "\n",
    "Implmentazione dello script di analisi della sommersione degli edifici (`wd_estimation.py`) in un recipe Python di Dataiku DSS.\n",
    "\n",
    "## Obiettivo\n",
    "Calcolare la percentuale di sommersione degli edifici durante eventi alluvionali analizzando la profondit√† dell'acqua nei pixel esterni al perimetro di ciascun edificio.\n",
    "\n",
    "## Input Dataiku\n",
    "- **Dataset**: `configurazione_parametri` - Contiene i parametri di configurazione (HEIGHT_FIELD, REPROJECTION_OPTION, TARGET_EPSG, BUFFER_DISTANCE)\n",
    "- **Dataset**: `configurazione_dati` - Contiene la selezione dei file di input (tipo_file, nome_file) per file vettoriali e raster specifici\n",
    "- **Folder**: `minio_input` - Folder Minio con file geospaziali organizzati in sottocartelle\n",
    "\n",
    "## Formati Supportati\n",
    "### üìÇ **Formati Vettoriali**:\n",
    "- **Shapefile** (`.shp`) - formato standard ESRI con file accessori\n",
    "- **GeoJSON** (`.geojson`, `.json`) - formato JSON geografico\n",
    "- **GeoPackage** (`.gpkg`) - formato moderno OGC \n",
    "- **GeoParquet** (`.parquet`, `.geoparquet`) - formato colonnare ottimizzato per performance\n",
    "- **KML** (`.kml`) - formato Google Earth\n",
    "- **GML** (`.gml`) - Geography Markup Language\n",
    "\n",
    "### üó∫Ô∏è **Formati Raster**:\n",
    "- **GeoTIFF** (`.tif`, `.tiff`) - formato standard georeferenziato\n",
    "- **ERDAS Imagine** (`.img`) - formato imaging professionale\n",
    "- **JPEG2000** (`.jp2`) - compressione avanzata con georiferimento\n",
    "- **Immagini standard** (`.png`, `.jpg`, `.jpeg`, `.bmp`, `.gif`) - con world file\n",
    "\n",
    "## Output Dataiku  \n",
    "- **Dataset**: `output_inondazioni` - DataFrame con risultati dell'analisi di sommersione\n",
    "- **Folder**: `output_inondazioni` - Folder con shapefile risultanti, report statistici e file di log\n",
    "\n",
    "## Metodologia\n",
    "L'analisi utilizza la tecnica del **campionamento esterno dei pixel** per determinare la profondit√† dell'acqua attorno agli edifici, calcolando statistiche di sommersione basate sul rapporto tra profondit√† media dell'acqua e altezza dell'edificio.\n",
    "\n",
    "### ‚ö†Ô∏è **Nota Tecnica - Buffer Distance**\n",
    "Il parametro `BUFFER_DISTANCE` definisce la distanza (in metri) del buffer attorno agli edifici per il campionamento dei pixel:\n",
    "- **Automatico** (`auto`): usa la risoluzione spaziale del raster (consigliato)\n",
    "- **Manuale**: valore in metri - **IMPORTANTE**: deve essere ‚â• 50% della risoluzione pixel per risultati affidabili\n",
    "- **Esempio**: con risoluzione 1m, buffer < 0.5m pu√≤ produrre campioni insufficienti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73afb239",
   "metadata": {},
   "source": [
    "## 1. Setup e Configurazione\n",
    "\n",
    "Import delle librerie necessarie e configurazione dei parametri dal dataset Dataiku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Import librerie di base\n",
    "import dataiku\n",
    "import pandas as pd, numpy as np\n",
    "from dataiku import pandasutils as pdu\n",
    "\n",
    "# Import librerie geospaziali\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from shapely.geometry import mapping\n",
    "from shapely.ops import unary_union\n",
    "import fiona\n",
    "\n",
    "# Import librerie di utilit√†\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import shutil\n",
    "import warnings\n",
    "from io import StringIO\n",
    "\n",
    "# Configurazione per sopprimere warning di librerie geospaziali\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\".*Input shapes do not overlap raster.*\")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*invalid value encountered.*\")\n",
    "\n",
    "# Classe per catturare le stampe SOLO nel log (senza output a schermo)\n",
    "class LogCapture:\n",
    "    def __init__(self):\n",
    "        self.log_buffer = StringIO()\n",
    "        self.original_stdout = sys.stdout\n",
    "        \n",
    "    def write(self, text):\n",
    "        # Scrivi SOLO nel buffer di log - niente a schermo\n",
    "        self.log_buffer.write(text)\n",
    "        \n",
    "    def flush(self):\n",
    "        self.log_buffer.flush()\n",
    "        \n",
    "    def get_log_content(self):\n",
    "        return self.log_buffer.getvalue()\n",
    "        \n",
    "    def clear_log(self):\n",
    "        self.log_buffer.close()\n",
    "        self.log_buffer = StringIO()\n",
    "        \n",
    "    def close(self):\n",
    "        self.log_buffer.close()\n",
    "\n",
    "# ATTIVA LOGGING GLOBALE PER CATTURARE TUTTE LE STAMPE\n",
    "# Ripristina stdout se gi√† attivo, poi ricrea il sistema di logging\n",
    "if 'log_capture' in globals():\n",
    "    sys.stdout = log_capture.original_stdout\n",
    "    log_capture.close()\n",
    "\n",
    "log_capture = LogCapture()\n",
    "sys.stdout = log_capture\n",
    "\n",
    "print(\"‚úÖ Tutte le librerie importate con successo\")\n",
    "print(\"üìù Sistema di logging attivato - OUTPUT NASCOSTO\")\n",
    "\n",
    "# Ripristina stdout per mostrare solo questo messaggio di conferma\n",
    "sys.stdout = log_capture.original_stdout\n",
    "print(\"üîá MODALIT√Ä SILENZIOSA ATTIVATA - Output nascosto (visibile solo nel log finale)\")\n",
    "sys.stdout = log_capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d1532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lettura dataset di configurazione\n",
    "configurazione_parametri = dataiku.Dataset(\"configurazione_parametri\")\n",
    "configurazione_parametri_df = configurazione_parametri.get_dataframe()\n",
    "\n",
    "print(\"=== DATASET CONFIGURAZIONE ===\")\n",
    "print(f\"Righe nel dataset: {len(configurazione_parametri_df)}\")\n",
    "print(f\"Colonne: {list(configurazione_parametri_df.columns)}\")\n",
    "print(configurazione_parametri_df.head())\n",
    "\n",
    "# Estrazione parametri dal dataset con la struttura: (variabile, valore)\n",
    "if 'variabile' in configurazione_parametri_df.columns and 'valore' in configurazione_parametri_df.columns:\n",
    "    # Crea dizionario dai dati del dataset\n",
    "    params_dict = dict(zip(configurazione_parametri_df['variabile'], configurazione_parametri_df['valore']))\n",
    "    \n",
    "    # Estrai i parametri (tutti string dal dataset)\n",
    "    HEIGHT_FIELD = params_dict[\"HEIGHT_FIELD\"]\n",
    "    REPROJECTION_OPTION = int(params_dict[\"REPROJECTION_OPTION\"])  # Converti a int\n",
    "    TARGET_EPSG = params_dict[\"TARGET_EPSG\"] \n",
    "    \n",
    "    # Gestione BUFFER_DISTANCE\n",
    "    buffer_val = params_dict[\"BUFFER_DISTANCE\"]\n",
    "    BUFFER_DISTANCE = None if str(buffer_val).lower() == \"auto\" else float(buffer_val)\n",
    "    \n",
    "else:\n",
    "    raise ValueError(\"‚ùå Dataset deve avere colonne 'variabile' e 'valore'!\")\n",
    "\n",
    "print(\"\\n=== PARAMETRI LETTI DAL DATASET ===\")\n",
    "print(f\"HEIGHT_FIELD: {HEIGHT_FIELD}\")\n",
    "print(f\"REPROJECTION_OPTION: {REPROJECTION_OPTION}\")\n",
    "print(f\"TARGET_EPSG: {TARGET_EPSG}\")\n",
    "print(f\"BUFFER_DISTANCE: {BUFFER_DISTANCE if BUFFER_DISTANCE is not None else 'auto (risoluzione pixel)'}\")\n",
    "print()\n",
    "\n",
    "# Legge il dataset di configurazione dati per selezione file\n",
    "configurazione_dati = dataiku.Dataset(\"configurazione_dati\")\n",
    "configurazione_dati_df = configurazione_dati.get_dataframe()\n",
    "\n",
    "print(\"\\n=== DATASET CONFIGURAZIONE DATI ===\\n\")\n",
    "print(f\"Righe nel dataset: {len(configurazione_dati_df)}\")\n",
    "print(f\"Colonne: {list(configurazione_dati_df.columns)}\")\n",
    "print(configurazione_dati_df)\n",
    "\n",
    "# Estrae i file configurati per tipo\n",
    "shapefile_config = configurazione_dati_df[configurazione_dati_df['tipo_file'] == 'vettoriale']['nome_file'].iloc[0]\n",
    "raster_config = configurazione_dati_df[configurazione_dati_df['tipo_file'] == 'raster']['nome_file'].iloc[0]\n",
    "\n",
    "print(f\"\\n=== FILE CONFIGURATI ===\\n\")\n",
    "print(f\"Shapefile configurato: {shapefile_config}\")\n",
    "print(f\"Raster configurato: {raster_config}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993b89e3",
   "metadata": {},
   "source": [
    "## 2. Carica Dati di Input da Dataiku\n",
    "\n",
    "Lettura dei parametri di configurazione dal dataset e accesso ai file vettoriali e raster dal folder Minio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1334c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accesso al folder di input contenente i file di analisi\n",
    "minio_input = dataiku.Folder(\"minio_input\")\n",
    "\n",
    "print(\"=== INFORMAZIONI FOLDER INPUT ===\")\n",
    "print(f\"Folder minio_input: {minio_input.get_info()}\")\n",
    "\n",
    "# Elenco dei file disponibili nel folder\n",
    "input_files = minio_input.list_paths_in_partition()\n",
    "\n",
    "print(f\"\\nFile disponibili nel folder minio_input:\")\n",
    "for file_path in input_files:\n",
    "    print(f\"  - {file_path}\")\n",
    "\n",
    "# DEFINIZIONE FORMATI SUPPORTATI\n",
    "# Formati vettoriali supportati da GeoPandas/Fiona\n",
    "VECTOR_EXTENSIONS = ['.shp', '.geojson', '.json', '.gpkg', '.parquet', '.geoparquet', '.kml', '.gml']\n",
    "# Formati raster supportati da Rasterio/GDAL  \n",
    "RASTER_EXTENSIONS = ['.tif', '.tiff', '.img', '.jp2', '.png', '.jpg', '.jpeg', '.bmp', '.gif']\n",
    "\n",
    "# Classificazione dei file per tipologia con supporto multi-formato\n",
    "vector_files = []\n",
    "raster_files = []\n",
    "\n",
    "for file_path in input_files:\n",
    "    file_lower = file_path.lower()\n",
    "    \n",
    "    # Controlla formati vettoriali\n",
    "    if any(file_lower.endswith(ext) for ext in VECTOR_EXTENSIONS):\n",
    "        vector_files.append(file_path)\n",
    "    \n",
    "    # Controlla formati raster\n",
    "    elif any(file_lower.endswith(ext) for ext in RASTER_EXTENSIONS):\n",
    "        raster_files.append(file_path)\n",
    "\n",
    "print(f\"\\n=== RIEPILOGO FILE PER TIPOLOGIA ===\")\n",
    "print(f\"File vettoriali trovati: {len(vector_files)}\")\n",
    "for vec in vector_files:\n",
    "    file_ext = '.' + vec.split('.')[-1].upper()\n",
    "    print(f\"  - {vec} [{file_ext}]\")\n",
    "\n",
    "print(f\"File raster trovati: {len(raster_files)}\")\n",
    "for ras in raster_files:\n",
    "    file_ext = '.' + ras.split('.')[-1].upper()\n",
    "    print(f\"  - {ras} [{file_ext}]\")\n",
    "\n",
    "# Verifica presenza dei file necessari\n",
    "if len(vector_files) == 0:\n",
    "    supported_vec = ', '.join(VECTOR_EXTENSIONS)\n",
    "    raise ValueError(f\"‚ùå Nessun file vettoriale trovato nel folder minio_input!\\n\"\n",
    "                    f\"Formati supportati: {supported_vec}\")\n",
    "                    \n",
    "if len(raster_files) == 0:\n",
    "    supported_ras = ', '.join(RASTER_EXTENSIONS)\n",
    "    raise ValueError(f\"‚ùå Nessun file raster trovato nel folder minio_input!\\n\"\n",
    "                    f\"Formati supportati: {supported_ras}\")\n",
    "\n",
    "print(f\"\\nüìã Formati vettoriali supportati: {', '.join(VECTOR_EXTENSIONS)}\")\n",
    "print(f\"üìã Formati raster supportati: {', '.join(RASTER_EXTENSIONS[:8])}... (+{len(RASTER_EXTENSIONS)-8} altri)\")\n",
    "\n",
    "# SELEZIONE INTELLIGENTE BASATA SU CONFIGURAZIONE\n",
    "def find_configured_file(file_list, configured_path, file_type):\n",
    "    \"\"\"Trova il file che corrisponde alla configurazione con percorso completo\"\"\"\n",
    "    # Estrai il nome del file dalla configurazione (dopo l'ultimo /)\n",
    "    configured_filename = configured_path.split('/')[-1]\n",
    "    \n",
    "    # Cerca corrispondenza esatta per nome file\n",
    "    exact_matches = [f for f in file_list if configured_filename in f]\n",
    "    if exact_matches:\n",
    "        print(f\"‚úì Trovato {file_type} configurato '{configured_filename}': {exact_matches[0]}\")\n",
    "        return exact_matches[0]\n",
    "    \n",
    "    # Cerca corrispondenza parziale nel percorso completo\n",
    "    path_matches = [f for f in file_list if configured_path.replace('/', '\\\\') in f or configured_path.replace('\\\\', '/') in f]\n",
    "    if path_matches:\n",
    "        print(f\"‚úì Trovato {file_type} con percorso '{configured_path}': {path_matches[0]}\")\n",
    "        return path_matches[0]\n",
    "    \n",
    "    # Se non trova corrispondenza, usa il primo e avvisa\n",
    "    print(f\"‚ö†Ô∏è  {file_type} configurato '{configured_path}' non trovato, uso il primo disponibile: {file_list[0]}\")\n",
    "    print(f\"   - File cercato: {configured_filename}\")\n",
    "    print(f\"   - Percorso cercato: {configured_path}\")\n",
    "    return file_list[0]\n",
    "\n",
    "print(f\"\\n=== SELEZIONE BASATA SU CONFIGURAZIONE ===\")\n",
    "print(f\"üìÅ File vettoriale configurato: {shapefile_config}\")\n",
    "print(f\"üìÅ File raster configurato: {raster_config}\")\n",
    "\n",
    "# Seleziona i file basandosi sulla configurazione (ora con nomi generici)\n",
    "vector_file = find_configured_file(vector_files, shapefile_config, \"file vettoriale\")\n",
    "raster_file = find_configured_file(raster_files, raster_config, \"file raster\")\n",
    "\n",
    "print(f\"\\n=== FILE SELEZIONATI PER L'ANALISI ===\\n\")\n",
    "print(f\"üìÑ File vettoriale: {vector_file}\")\n",
    "print(f\"üó∫Ô∏è  File raster: {raster_file}\")\n",
    "\n",
    "# Mostra file alternativi disponibili\n",
    "if len(vector_files) > 1:\n",
    "    print(f\"\\nüìã Altri file vettoriali disponibili:\")\n",
    "    for vec in vector_files:\n",
    "        if vec != vector_file:\n",
    "            file_ext = '.' + vec.split('.')[-1].upper()\n",
    "            print(f\"   - {vec} [{file_ext}]\")\n",
    "\n",
    "if len(raster_files) > 1:\n",
    "    print(f\"\\nüìã Altri file raster disponibili:\")\n",
    "    for ras in raster_files:\n",
    "        if ras != raster_file:\n",
    "            file_ext = '.' + ras.split('.')[-1].upper()\n",
    "            print(f\"   - {ras} [{file_ext}]\")\n",
    "\n",
    "print(f\"\\nüí° Per cambiare selezione, modifica il dataset 'configurazione_dati'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3dfe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dei file dal folder di input verso directory temporanea locale\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "print(f\"Directory temporanea creata: {temp_dir}\")\n",
    "\n",
    "# Definizione percorsi locali per i file selezionati\n",
    "vector_local_path = os.path.join(temp_dir, os.path.basename(vector_file))\n",
    "raster_local_path = os.path.join(temp_dir, os.path.basename(raster_file))\n",
    "\n",
    "# Scaricamento file vettoriale principale\n",
    "print(f\"Download in corso: {vector_file}\")\n",
    "with open(vector_local_path, 'wb') as f:\n",
    "    f.write(minio_input.get_download_stream(vector_file).read())\n",
    "\n",
    "# Scaricamento file raster\n",
    "print(f\"Download in corso: {raster_file}\")\n",
    "with open(raster_local_path, 'wb') as f:\n",
    "    f.write(minio_input.get_download_stream(raster_file).read())\n",
    "\n",
    "# Scaricamento file accessori per shapefile (se il file vettoriale √® uno shapefile)\n",
    "if vector_file.lower().endswith('.shp'):\n",
    "    print(f\"üìÅ Rilevato Shapefile - scaricamento file accessori...\")\n",
    "    shapefile_extensions = ['.dbf', '.shx', '.prj', '.qix', '.xml', '.cpg', '.sbx', '.sbn']\n",
    "    \n",
    "    for ext in shapefile_extensions:\n",
    "        aux_file = vector_file.replace('.shp', ext).replace('.SHP', ext)\n",
    "        if aux_file in input_files:\n",
    "            aux_local_path = os.path.join(temp_dir, os.path.basename(aux_file))\n",
    "            print(f\"Download file accessorio: {aux_file}\")\n",
    "            with open(aux_local_path, 'wb') as f:\n",
    "                f.write(minio_input.get_download_stream(aux_file).read())\n",
    "            print(f\"Completato: {os.path.basename(aux_file)}\")\n",
    "\n",
    "# Scaricamento file accessori per altri formati (se presenti)\n",
    "elif vector_file.lower().endswith(('.gpkg', '.gdb')):\n",
    "    print(f\"üìÅ File vettoriale database rilevato - formato autocontenuto\")\n",
    "    \n",
    "elif vector_file.lower().endswith(('.parquet', '.geoparquet')):\n",
    "    print(f\"üìÅ File GeoParquet rilevato - formato colonnare ottimizzato\")\n",
    "    \n",
    "else:\n",
    "    vector_ext = vector_file.split('.')[-1].upper()\n",
    "    print(f\"üìÅ File vettoriale {vector_ext} - formato autocontenuto\")\n",
    "\n",
    "# Informazioni sui file raster\n",
    "raster_ext = raster_file.split('.')[-1].upper() \n",
    "print(f\"üìÅ File raster {raster_ext} scaricato\")\n",
    "\n",
    "print(f\"\\n=== DOWNLOAD COMPLETATO ===\")\n",
    "print(f\"File vettoriale: {vector_local_path}\")\n",
    "print(f\"File raster: {raster_local_path}\")\n",
    "print(f\"Directory di lavoro: {temp_dir}\")\n",
    "print(f\"Formato vettoriale: {vector_file.split('.')[-1].upper()}\")\n",
    "print(f\"Formato raster: {raster_file.split('.')[-1].upper()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9790086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica dati vettoriali e raster con geopandas e rasterio\n",
    "vector = gpd.read_file(vector_local_path)\n",
    "raster = rasterio.open(raster_local_path)\n",
    "\n",
    "print(\"=== DATI CARICATI ===\")\n",
    "print(f\"Edifici nel vettoriale: {len(vector)}\")\n",
    "print(f\"Dimensioni raster: {raster.width} x {raster.height}\")\n",
    "print(f\"CRS vettoriale: {vector.crs}\")\n",
    "print(f\"CRS raster: {raster.crs}\")\n",
    "\n",
    "# Controlla i campi disponibili nel vettoriale\n",
    "print(f\"\\nCampi disponibili nel vettoriale:\")\n",
    "print(list(vector.columns))\n",
    "\n",
    "# Verifica che il campo altezza sia presente\n",
    "if HEIGHT_FIELD not in vector.columns:\n",
    "    raise ValueError(f\"Campo altezza '{HEIGHT_FIELD}' non trovato nel vettoriale! Campi disponibili: {list(vector.columns)}\")\n",
    "    \n",
    "print(f\"\\n‚úì Campo altezza '{HEIGHT_FIELD}' trovato nel vettoriale\")\n",
    "\n",
    "# Rilevamento campo FID (case-insensitive)\n",
    "FID_FIELD = None\n",
    "fid_value_source = None\n",
    "for col in vector.columns:\n",
    "    if col.upper() == 'FID':\n",
    "        FID_FIELD = col\n",
    "        fid_value_source = 'input'  # Eredita dall'input\n",
    "        break\n",
    "\n",
    "if FID_FIELD:\n",
    "    print(f\"‚úì Campo FID trovato nell'input: '{FID_FIELD}' - sar√† ereditato\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  Campo FID non presente nell'input - sar√† generato automaticamente\")\n",
    "    fid_value_source = 'generated'  # Genera automaticamente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6dbba7",
   "metadata": {},
   "source": [
    "## 3. Allineamento Sistemi di Riferimento\n",
    "\n",
    "Controllo della compatibilit√† CRS tra dati vettoriali e raster e implementazione della logica di riproiezione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c71d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controllo CRS\n",
    "vector_crs = vector.crs\n",
    "raster_crs = raster.crs\n",
    "\n",
    "if vector_crs != raster_crs:\n",
    "    print(f\"‚ö†Ô∏è  ATTENZIONE: I sistemi di riferimento non coincidono!\")\n",
    "    print(f\"CRS vettoriale: {vector_crs}\")\n",
    "    print(f\"CRS raster: {raster_crs}\")\n",
    "    print(f\"Applicando opzione di riproiezione: {REPROJECTION_OPTION}\")\n",
    "    \n",
    "    try:\n",
    "        if REPROJECTION_OPTION == 1:\n",
    "            # Riproietta vettoriale nel CRS del raster\n",
    "            target_crs = raster_crs\n",
    "            print(f\"Riproiettando il vettoriale in {target_crs}...\")\n",
    "            vector = vector.to_crs(target_crs)\n",
    "            print(\"‚úì Vettoriale riproiettato.\")\n",
    "            \n",
    "        elif REPROJECTION_OPTION == 2:\n",
    "            # Riproietta raster nel CRS del vettoriale\n",
    "            target_crs = vector_crs\n",
    "            print(f\"Riproiettando il raster in {target_crs}...\")\n",
    "            # Crea file temporaneo per raster riproiettato\n",
    "            temp_raster = tempfile.NamedTemporaryFile(suffix='.tif', delete=False)\n",
    "            temp_raster_path = temp_raster.name\n",
    "            temp_raster.close()\n",
    "            \n",
    "            # Calcola trasformazione\n",
    "            transform, width, height = calculate_default_transform(\n",
    "                raster.crs, target_crs, raster.width, raster.height, *raster.bounds)\n",
    "            \n",
    "            # Parametri per il nuovo raster\n",
    "            kwargs = raster.meta.copy()\n",
    "            kwargs.update({\n",
    "                'crs': target_crs,\n",
    "                'transform': transform,\n",
    "                'width': width,\n",
    "                'height': height\n",
    "            })\n",
    "            \n",
    "            # Esegui riproiezione\n",
    "            with rasterio.open(temp_raster_path, 'w', **kwargs) as dst:\n",
    "                for i in range(1, raster.count + 1):\n",
    "                    reproject(\n",
    "                        source=rasterio.band(raster, i),\n",
    "                        destination=rasterio.band(dst, i),\n",
    "                        src_transform=raster.transform,\n",
    "                        src_crs=raster.crs,\n",
    "                        dst_transform=transform,\n",
    "                        dst_crs=target_crs,\n",
    "                        resampling=Resampling.bilinear)\n",
    "            \n",
    "            # Chiudi raster originale e apri quello riproiettato\n",
    "            raster.close()\n",
    "            raster = rasterio.open(temp_raster_path)\n",
    "            print(\"‚úì Raster riproiettato.\")\n",
    "            \n",
    "        elif REPROJECTION_OPTION == 3:\n",
    "            # Riproietta entrambi nel CRS specificato\n",
    "            target_crs = f\"EPSG:{TARGET_EPSG}\"\n",
    "            print(f\"Riproiettando entrambi in {target_crs}...\")\n",
    "            \n",
    "            # Riproietta vettoriale\n",
    "            vector = vector.to_crs(target_crs)\n",
    "            print(\"‚úì Vettoriale riproiettato.\")\n",
    "            \n",
    "            # Riproietta raster (stesso codice dell'opzione 2)\n",
    "            temp_raster = tempfile.NamedTemporaryFile(suffix='.tif', delete=False)\n",
    "            temp_raster_path = temp_raster.name\n",
    "            temp_raster.close()\n",
    "            \n",
    "            transform, width, height = calculate_default_transform(\n",
    "                raster.crs, target_crs, raster.width, raster.height, *raster.bounds)\n",
    "            \n",
    "            kwargs = raster.meta.copy()\n",
    "            kwargs.update({\n",
    "                'crs': target_crs,\n",
    "                'transform': transform,\n",
    "                'width': width,\n",
    "                'height': height\n",
    "            })\n",
    "            \n",
    "            with rasterio.open(temp_raster_path, 'w', **kwargs) as dst:\n",
    "                for i in range(1, raster.count + 1):\n",
    "                    reproject(\n",
    "                        source=rasterio.band(raster, i),\n",
    "                        destination=rasterio.band(dst, i),\n",
    "                        src_transform=raster.transform,\n",
    "                        src_crs=raster.crs,\n",
    "                        dst_transform=transform,\n",
    "                        dst_crs=target_crs,\n",
    "                        resampling=Resampling.bilinear)\n",
    "            \n",
    "            raster.close()\n",
    "            raster = rasterio.open(temp_raster_path)\n",
    "            print(\"‚úì Raster riproiettato.\")\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Opzione di riproiezione non valida: {REPROJECTION_OPTION}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Errore durante la riproiezione: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚úì Sistemi di riferimento gi√† compatibili - nessuna riproiezione necessaria\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3a217d",
   "metadata": {},
   "source": [
    "## 4. Funzioni di Analisi della Profondit√† dell'Acqua\n",
    "\n",
    "Implementazione della funzione `get_external_pixels()` per estrarre i valori di profondit√† dell'acqua dai pixel immediatamente esterni al perimetro degli edifici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf5d2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_external_pixels(geom, raster, buffer_distance=None):\n",
    "    \"\"\"\n",
    "    Estrae i valori dei pixel immediatamente esterni al perimetro del poligono\n",
    "    \n",
    "    Parametri:\n",
    "    - geom: geometria del poligono (edificio)  \n",
    "    - raster: rasterio dataset con profondit√† acqua\n",
    "    - buffer_distance: distanza buffer in metri (None = automatico = risoluzione pixel)\n",
    "    \n",
    "    Ritorna:\n",
    "    - numpy array con valori di profondit√† validi\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Disabilita temporaneamente tutti i warning per evitare messaggi di sovrapposizione\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            \n",
    "            # Se non specificato, usa la risoluzione del raster come buffer\n",
    "            if buffer_distance is None:\n",
    "                buffer_distance = abs(raster.transform[0])  # risoluzione pixel\n",
    "            \n",
    "            # Crea buffer esterno molto piccolo\n",
    "            external_buffer = geom.buffer(buffer_distance)\n",
    "            \n",
    "            # Crea anello: buffer esterno - poligono originale\n",
    "            ring = external_buffer.difference(geom)\n",
    "            \n",
    "            # Estrai valori raster dall'anello - questa chiamata pu√≤ generare il warning\n",
    "            out_image, out_transform = rasterio.mask.mask(raster, [mapping(ring)], crop=True, filled=True)\n",
    "            data = out_image[0]\n",
    "            \n",
    "            # Escludi nodata\n",
    "            valid_data = data[data != raster.nodata]\n",
    "            \n",
    "            return valid_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Gestione silenziosa degli errori comuni (es. nessuna sovrapposizione)\n",
    "        # Gli errori saranno tracciati nel conteggio generale\n",
    "        return np.array([])\n",
    "\n",
    "print(\"‚úì Funzione get_external_pixels() definita con soppressione warning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2400184",
   "metadata": {},
   "source": [
    "## 5. Calcolo della Sommersione degli Edifici\n",
    "\n",
    "Elaborazione di ogni edificio per calcolare area, volume e statistiche di sommersione con tracking del progresso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40308ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara lista risultati e contatori dettagliati\n",
    "results = []\n",
    "processed_count = 0\n",
    "not_processed_count = 0\n",
    "no_overlap_count = 0  # Edifici senza sovrapposizione con raster\n",
    "zero_height_count = 0  # Edifici con altezza zero/negativa\n",
    "other_errors_count = 0  # Altri errori\n",
    "\n",
    "print(f\"üöÄ Inizio elaborazione di {len(vector)} edifici...\")\n",
    "print(f\"Buffer distance: {BUFFER_DISTANCE} (None = automatico)\")\n",
    "\n",
    "for idx, row in vector.iterrows():\n",
    "    geom = row.geometry\n",
    "    a_base = geom.area  # Calcola area dalla geometria\n",
    "    h_uvl = row[HEIGHT_FIELD]  # Legge altezza dal campo parametrizzato\n",
    "    vol = a_base * h_uvl\n",
    "    \n",
    "    # Controlla validit√† altezza prima dell'estrazione\n",
    "    if h_uvl <= 0:\n",
    "        zero_height_count += 1\n",
    "        depth_mean = 0.0\n",
    "        depth_min = 0.0\n",
    "        depth_max = 0.0\n",
    "        perc_submerged = 0.0\n",
    "        not_processed_count += 1\n",
    "    else:\n",
    "        # Estrai valori esterni al perimetro\n",
    "        external_values = get_external_pixels(geom, raster, BUFFER_DISTANCE)\n",
    "        \n",
    "        if external_values.size > 0:\n",
    "            # Calcola statistiche di sommersione\n",
    "            depth_mean = np.mean(external_values)\n",
    "            depth_min = np.min(external_values)\n",
    "            depth_max = np.max(external_values)\n",
    "            \n",
    "            # Calcola percentuale di sommersione basata sulla quota media\n",
    "            perc_submerged = min((depth_mean / h_uvl) * 100, 100.0)\n",
    "            \n",
    "            processed_count += 1\n",
    "        else:\n",
    "            # Nessun dato valido - probabilmente nessuna sovrapposizione\n",
    "            no_overlap_count += 1\n",
    "            depth_mean = 0.0\n",
    "            depth_min = 0.0\n",
    "            depth_max = 0.0\n",
    "            perc_submerged = 0.0\n",
    "            not_processed_count += 1\n",
    "    \n",
    "    # Gestione campo FID\n",
    "    if fid_value_source == 'input':\n",
    "        fid_value = row[FID_FIELD]  # Eredita dall'input\n",
    "    else:\n",
    "        fid_value = idx + 1  # Genera FID sequenziale (1-based)\n",
    "    \n",
    "    # Crea record risultato - include FID\n",
    "    result_record = {\n",
    "        'FID': fid_value,\n",
    "        'A_BASE': round(a_base, 2),\n",
    "        HEIGHT_FIELD: round(h_uvl, 2),\n",
    "        'VOL': round(vol, 2),\n",
    "        'DEPTH_MEAN': round(depth_mean, 2),\n",
    "        'DEPTH_MIN': round(depth_min, 2),\n",
    "        'DEPTH_MAX': round(depth_max, 2),\n",
    "        'PERC_SUBM': round(perc_submerged, 2),\n",
    "        'geometry': geom\n",
    "    }\n",
    "    \n",
    "    results.append(result_record)\n",
    "    \n",
    "    # Progress indicator\n",
    "    if (idx + 1) % 100 == 0:\n",
    "        print(f\"üìä Elaborati {idx + 1}/{len(vector)} edifici...\")\n",
    "\n",
    "print(f\"‚úÖ Elaborazione completata!\")\n",
    "print(f\"Edifici processati con successo: {processed_count}\")\n",
    "print(f\"Edifici non processati: {not_processed_count}\")\n",
    "if not_processed_count > 0:\n",
    "    print(f\"  ‚îî‚îÄ Senza sovrapposizione con raster: {no_overlap_count}\")\n",
    "    print(f\"  ‚îî‚îÄ Altezza zero/negativa: {zero_height_count}\")\n",
    "    if other_errors_count > 0:\n",
    "        print(f\"  ‚îî‚îÄ Altri errori: {other_errors_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ea1e97",
   "metadata": {},
   "source": [
    "## 6. Preparazione Output\n",
    "\n",
    "Creazione del GeoDataFrame di output con i risultati dell'analisi di sommersione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a9dbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea GeoDataFrame di output\n",
    "out_gdf = gpd.GeoDataFrame(results, crs=vector.crs)\n",
    "total_buildings = len(vector)  # Variabile necessaria per il report\n",
    "\n",
    "print(f\"‚úì GeoDataFrame di output pronto: {len(out_gdf)} record con campi analisi aggiunti\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040db3ad",
   "metadata": {},
   "source": [
    "## 7. Generazione Output\n",
    "\n",
    "Creazione del DataFrame di output con schema appropriato e scrittura nel dataset Dataiku di destinazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6358d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converti GeoDataFrame in DataFrame standard per Dataiku\n",
    "output_inondazioni_df = pd.DataFrame(out_gdf.drop(columns='geometry'))\n",
    "\n",
    "# Aggiungi colonna WKT come prima colonna per il CSV\n",
    "output_inondazioni_df.insert(0, 'geometry_wkt', out_gdf['geometry'].apply(lambda x: x.wkt))\n",
    "\n",
    "# Assicura che FID sia la seconda colonna\n",
    "if 'FID' in output_inondazioni_df.columns:\n",
    "    fid_col = output_inondazioni_df.pop('FID')\n",
    "    output_inondazioni_df.insert(1, 'FID', fid_col)\n",
    "\n",
    "print(f\"üìã DataFrame per output Dataiku:\")\n",
    "print(f\"   Righe: {len(output_inondazioni_df)}\")\n",
    "print(f\"   Colonne: {len(output_inondazioni_df.columns)}\")\n",
    "print(f\"   Colonne: {list(output_inondazioni_df.columns)}\")\n",
    "\n",
    "# Mostra esempio primi record\n",
    "print(f\"\\nüìä Esempio primi 3 record:\")\n",
    "print(output_inondazioni_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45f7c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio risultati come CSV\n",
    "print(\"üìù Salvataggio file CSV...\")\n",
    "\n",
    "italian_tz = pytz.timezone('Europe/Rome')\n",
    "timestamp = datetime.now(italian_tz).strftime(\"%Y%m%d_%H%M%S\") \n",
    "csv_filename = f\"risultati_inondazioni_{timestamp}.csv\"\n",
    "\n",
    "try:\n",
    "    output_folder = dataiku.Folder(\"output_inondazioni\")\n",
    "    csv_content = output_inondazioni_df.to_csv(index=False)\n",
    "    \n",
    "    from io import StringIO\n",
    "    csv_stream = StringIO(csv_content)\n",
    "    output_folder.upload_stream(csv_filename, csv_stream.getvalue().encode('utf-8'))\n",
    "    \n",
    "    print(f\"‚úÖ File CSV salvato: {csv_filename}\")\n",
    "    print(f\"‚úÖ {len(output_inondazioni_df)} record salvati\")\n",
    "    \n",
    "except Exception as e:\n",
    "    local_csv = f\"C:\\\\temp\\\\{csv_filename}\"\n",
    "    output_inondazioni_df.to_csv(local_csv, index=False)\n",
    "    print(f\"‚úÖ File salvato in locale: {local_csv}\")\n",
    "    print(f\"‚úÖ {len(output_inondazioni_df)} record salvati\")\n",
    "\n",
    "print(\"‚úÖ ELABORAZIONE COMPLETATA\")\n",
    "print(f\"‚úÖ Dataset 'output_inondazioni' scritto con {len(output_inondazioni_df)} record\")\n",
    "print(f\"‚úÖ Analisi di sommersione completata per {processed_count}/{total_buildings} edifici\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51707651",
   "metadata": {},
   "source": [
    "## 8. Salvataggio File Fisici\n",
    "\n",
    "Salvataggio di shapefile, report statistico e upload nel folder Dataiku di output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62de9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurazione folder di output per il salvataggio dei risultati\n",
    "output_folder = dataiku.Folder(\"output_inondazioni\")\n",
    "\n",
    "# Creazione directory temporanea per i file di output\n",
    "output_temp_dir = tempfile.mkdtemp()\n",
    "print(f\"Directory temporanea per output: {output_temp_dir}\")\n",
    "\n",
    "# Generazione nome base per i file di output con timestamp\n",
    "italian_tz = pytz.timezone('Europe/Rome')\n",
    "timestamp = datetime.now(italian_tz).strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_base_name = f\"wd_analysis_{timestamp}\"\n",
    "\n",
    "# Definizione percorsi dei file di output\n",
    "shapefile_path = os.path.join(output_temp_dir, f\"{output_base_name}.shp\")\n",
    "report_path = os.path.join(output_temp_dir, f\"{output_base_name}_report.txt\")\n",
    "log_path = os.path.join(output_temp_dir, f\"{output_base_name}.log\")\n",
    "\n",
    "print(f\"File di output programmati:\")\n",
    "print(f\"   Shapefile: {os.path.basename(shapefile_path)}\")\n",
    "print(f\"   Report statistico: {os.path.basename(report_path)}\")\n",
    "print(f\"   Log elaborazione: {os.path.basename(log_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d834d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva vettoriale con schema definito (include FID)\n",
    "schema = {\n",
    "    'geometry': 'Polygon',\n",
    "    'properties': {\n",
    "        'FID': 'int:10',             # Campo identificativo\n",
    "        'A_BASE': 'float:10.2',      # 10 cifre totali, 2 decimali\n",
    "        HEIGHT_FIELD: 'float:8.2',   # 8 cifre totali, 2 decimali  \n",
    "        'VOL': 'float:12.2',         # 12 cifre totali, 2 decimali\n",
    "        'DEPTH_MEAN': 'float:8.2',   # 8 cifre totali, 2 decimali\n",
    "        'DEPTH_MIN': 'float:8.2',    # 8 cifre totali, 2 decimali\n",
    "        'DEPTH_MAX': 'float:8.2',    # 8 cifre totali, 2 decimali\n",
    "        'PERC_SUBM': 'float:6.2'     # 6 cifre totali, 2 decimali\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"üíæ Salvataggio vettoriale...\")\n",
    "with fiona.open(shapefile_path, 'w', driver='ESRI Shapefile', crs=out_gdf.crs, schema=schema) as f:\n",
    "    for idx, row in out_gdf.iterrows():\n",
    "        feature = {\n",
    "            'geometry': mapping(row.geometry),\n",
    "            'properties': {\n",
    "                'FID': int(row['FID']),\n",
    "                'A_BASE': float(row['A_BASE']),\n",
    "                HEIGHT_FIELD: float(row[HEIGHT_FIELD]),\n",
    "                'VOL': float(row['VOL']),\n",
    "                'DEPTH_MEAN': float(row['DEPTH_MEAN']),\n",
    "                'DEPTH_MIN': float(row['DEPTH_MIN']),\n",
    "                'DEPTH_MAX': float(row['DEPTH_MAX']),\n",
    "                'PERC_SUBM': float(row['PERC_SUBM'])\n",
    "            }\n",
    "        }\n",
    "        f.write(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a2a689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea report statistico dettagliato\n",
    "print(\"üìä Generazione report statistico...\")\n",
    "\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"=== REPORT ANALISI SOMMERSIONE EDIFICI ===\\n\\n\")\n",
    "    f.write(f\"Data elaborazione: {datetime.now(pytz.timezone('Europe/Rome')).strftime('%Y-%m-%d %H:%M:%S')} (Ora italiana)\\n\")\n",
    "    f.write(f\"Versione script: dataiku_integration.ipynb\\n\")\n",
    "    f.write(f\"Campo altezza utilizzato: {HEIGHT_FIELD}\\n\")\n",
    "    f.write(f\"Opzione riproiezione: {REPROJECTION_OPTION} \")\n",
    "    if REPROJECTION_OPTION == 1:\n",
    "        f.write(\"(riproietta vettoriale)\\n\")\n",
    "    elif REPROJECTION_OPTION == 2:\n",
    "        f.write(\"(riproietta raster)\\n\")\n",
    "    else:\n",
    "        f.write(f\"(riproietta entrambi in {TARGET_EPSG})\\n\")\n",
    "    f.write(f\"Buffer distance: {BUFFER_DISTANCE}\\n\\n\")\n",
    "    \n",
    "    f.write(\"=== FILE DI INPUT/OUTPUT ===\\n\")\n",
    "    f.write(f\"File vettoriale: {vector_file}\\n\")\n",
    "    f.write(f\"File raster: {raster_file}\\n\")\n",
    "    f.write(f\"File output shapefile: {os.path.basename(shapefile_path)}\\n\")\n",
    "    f.write(f\"File output report: {os.path.basename(report_path)}\\n\\n\")\n",
    "    \n",
    "    f.write(\"=== SISTEMI DI RIFERIMENTO ===\\n\")\n",
    "    f.write(f\"CRS vettoriale originale: {vector_crs}\\n\")\n",
    "    f.write(f\"CRS raster: {raster_crs}\\n\")\n",
    "    if vector_crs != raster_crs:\n",
    "        f.write(\"NOTA: Sistemi di riferimento diversi - applicata riproiezione automatica\\n\")\n",
    "    else:\n",
    "        f.write(\"NOTA: Sistemi di riferimento coincidenti - nessuna riproiezione necessaria\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"=== RIEPILOGO ELABORAZIONE ===\\n\")\n",
    "    f.write(f\"Edifici totali nel vettoriale: {total_buildings}\\n\")\n",
    "    f.write(f\"Edifici processati con successo: {processed_count} ({processed_count/total_buildings*100:.1f}%)\\n\")\n",
    "    f.write(f\"Edifici non processati: {not_processed_count} ({not_processed_count/total_buildings*100:.1f}%)\\n\")\n",
    "    f.write(f\"  - Cause: senza sovrapposizione con raster, altezza zero/negativa, errori geometrici\\n\\n\")\n",
    "    \n",
    "    f.write(\"=== METODOLOGIA ===\\n\")\n",
    "    f.write(\"L'analisi calcola la sommersione degli edifici campionando i valori di profondit√†\\n\")\n",
    "    f.write(\"dell'acqua nei pixel esterni al perimetro di ciascun edificio.\\n\")\n",
    "    f.write(\"La percentuale di sommersione √® calcolata come: (profondit√†_media / altezza_edificio) √ó 100\\n\")\n",
    "    f.write(\"I valori sono limitati al 100% per edifici completamente sommersi.\\n\\n\")\n",
    "    \n",
    "    # Statistiche dettagliate se ci sono edifici processati\n",
    "    if processed_count > 0:\n",
    "        processed_data = out_gdf[out_gdf['DEPTH_MEAN'] > 0]\n",
    "        \n",
    "        if len(processed_data) > 0:\n",
    "            f.write(f\"Edifici con sommersione rilevata: {len(processed_data)} ({len(processed_data)/total_buildings*100:.1f}%)\\n\\n\")\n",
    "            \n",
    "            # Statistiche profondit√†\n",
    "            mean_depth = processed_data['DEPTH_MEAN'].mean()  \n",
    "            max_depth = processed_data['DEPTH_MAX'].max()\n",
    "            min_depth = processed_data['DEPTH_MIN'].min()\n",
    "            \n",
    "            f.write(\"=== PROFONDIT√Ä ACQUA ===\\n\")\n",
    "            f.write(f\"Profondit√† media: {mean_depth:.2f} m (range: {min_depth:.2f} - {max_depth:.2f} m)\\n\\n\")\n",
    "            \n",
    "            # Classificazione edifici\n",
    "            edifici_bassi = len(processed_data[processed_data['PERC_SUBM'] < 25])\n",
    "            edifici_medi = len(processed_data[(processed_data['PERC_SUBM'] >= 25) & (processed_data['PERC_SUBM'] < 75)])\n",
    "            edifici_alti = len(processed_data[processed_data['PERC_SUBM'] >= 75])\n",
    "            \n",
    "            f.write(\"=== CLASSIFICAZIONE EDIFICI PER LIVELLO SOMMERSIONE ===\\n\")\n",
    "            f.write(f\"Sommersione bassa (<25%): {edifici_bassi} edifici ({edifici_bassi/len(processed_data)*100:.1f}%)\\n\")\n",
    "            f.write(f\"Sommersione media (25-75%): {edifici_medi} edifici ({edifici_medi/len(processed_data)*100:.1f}%)\\n\")\n",
    "            f.write(f\"Sommersione alta (‚â•75%): {edifici_alti} edifici ({edifici_alti/len(processed_data)*100:.1f}%)\\n\\n\")\n",
    "    \n",
    "    f.write(\"=== CAMPI OUTPUT VETTORIALE ===\\n\")\n",
    "    fid_source_text = \"ereditato dall'input\" if fid_value_source == 'input' else 'generato automaticamente'\n",
    "    f.write(f\"FID: Identificativo univoco edificio ({fid_source_text})\\n\")\n",
    "    f.write(\"DEPTH_MEAN: Profondit√† media dell'acqua attorno all'edificio (m)\\n\")\n",
    "    f.write(\"DEPTH_MAX: Profondit√† massima dell'acqua attorno all'edificio (m)\\n\")\n",
    "    f.write(\"DEPTH_MIN: Profondit√† minima dell'acqua attorno all'edificio (m)\\n\")\n",
    "    f.write(\"PERC_SUBM: Percentuale di sommersione dell'edificio (%)\\n\")\n",
    "    f.write(f\"{HEIGHT_FIELD}: Altezza dell'edificio utilizzata nel calcolo (m)\\n\")\n",
    "    f.write(\"A_BASE: Area della base dell'edificio (m¬≤)\\n\")\n",
    "    f.write(\"VOL: Volume dell'edificio (m¬≥)\\n\")\n",
    "\n",
    "print(f\"‚úÖ Report salvato: {os.path.basename(report_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2836e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea il file di log con TUTTE le stampe catturate\n",
    "print(\"üìù Generazione file di log completo...\")\n",
    "with open(log_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(f\"=== LOG ELABORAZIONE ANALISI SOMMERSIONE EDIFICI ===\\n\\n\")\n",
    "    f.write(f\"Data elaborazione: {datetime.now(pytz.timezone('Europe/Rome')).strftime('%Y-%m-%d %H:%M:%S')} (Ora italiana)\\n\")\n",
    "    f.write(f\"Versione script: dataiku_integration.ipynb\\n\")\n",
    "    f.write(f\"Parametri utilizzati:\\n\")\n",
    "    f.write(f\"  - HEIGHT_FIELD: {HEIGHT_FIELD}\\n\")\n",
    "    f.write(f\"  - REPROJECTION_OPTION: {REPROJECTION_OPTION}\\n\")\n",
    "    f.write(f\"  - TARGET_EPSG: {TARGET_EPSG}\\n\")\n",
    "    f.write(f\"  - BUFFER_DISTANCE: {BUFFER_DISTANCE}\\n\")\n",
    "    f.write(f\"\\n=== TRANSCRIPT ESECUZIONE ===\\n\\n\")\n",
    "    f.write(log_capture.get_log_content())\n",
    "    f.write(f\"\\n=== FINE LOG ===\\n\")\n",
    "\n",
    "# Upload dei file di output nel folder Dataiku\n",
    "print(\"üì§ Upload file nel folder Dataiku di output...\")\n",
    "\n",
    "# Lista di tutti i file da caricare (shapefile + accessori + report + log)\n",
    "files_to_upload = []\n",
    "\n",
    "# Shapefile principale\n",
    "files_to_upload.append(shapefile_path)\n",
    "# File accessori shapefile\n",
    "for ext in ['.dbf', '.shx', '.prj', '.cpg']:\n",
    "    aux_file = shapefile_path.replace('.shp', ext)\n",
    "    if os.path.exists(aux_file):\n",
    "        files_to_upload.append(aux_file)\n",
    "\n",
    "# Report\n",
    "files_to_upload.append(report_path)\n",
    "\n",
    "# File di log\n",
    "files_to_upload.append(log_path)\n",
    "\n",
    "# Upload dei file\n",
    "uploaded_files = []\n",
    "for file_path in files_to_upload:\n",
    "    if os.path.exists(file_path):\n",
    "        file_name = os.path.basename(file_path)\n",
    "        try:\n",
    "            with open(file_path, 'rb') as f:\n",
    "                output_folder.upload_stream(file_name, f)\n",
    "            uploaded_files.append(file_name)\n",
    "        except Exception as e:\n",
    "            pass  # Gestione silenziosa degli errori\n",
    "\n",
    "# Aggiorna il log con le informazioni di upload\n",
    "with open(log_path, 'a', encoding='utf-8') as f:\n",
    "    f.write(f\"\\n=== OPERAZIONI DI UPLOAD ===\\n\\n\")\n",
    "    f.write(f\"üì§ Upload completato nel folder 'minio/output'\\n\")\n",
    "    f.write(f\"üìÅ File caricati: {len(uploaded_files)}\\n\")\n",
    "    for filename in uploaded_files:\n",
    "        f.write(f\"   ‚úÖ {filename}\\n\")\n",
    "    f.write(f\"\\nüéâ SALVATAGGIO COMPLETATO!\\n\")\n",
    "\n",
    "# Re-upload del log aggiornato\n",
    "try:\n",
    "    with open(log_path, 'rb') as f:\n",
    "        output_folder.upload_stream(os.path.basename(log_path), f)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Pulizia directory temporanea output  \n",
    "try:\n",
    "    shutil.rmtree(output_temp_dir)\n",
    "except Exception as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6894601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulizia risorse e file temporanei\n",
    "try:\n",
    "    raster.close()\n",
    "    if 'temp_raster_path' in locals():\n",
    "        try:\n",
    "            os.unlink(temp_raster_path)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Pulizia directory temporanea\n",
    "    try:\n",
    "        shutil.rmtree(temp_dir)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "except Exception as e:\n",
    "    pass\n",
    "\n",
    "# Ripristina stdout originale e chiudi il sistema di logging\n",
    "sys.stdout = log_capture.original_stdout\n",
    "log_capture.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
